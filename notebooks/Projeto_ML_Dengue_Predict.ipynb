{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ac5fc2-caa2-4e98-82f8-439f42bdd127",
   "metadata": {},
   "source": [
    "![](https://hackmd.io/_uploads/H1ZOOXMRh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d3c97-c310-4d0b-924c-322d39fae37a",
   "metadata": {},
   "source": [
    "### Projeto I - Aplicação de Métodos de Aprendizagem de Máquina\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737098f2-d12e-4f14-9d35-b945d21fb828",
   "metadata": {},
   "source": [
    "\n",
    "| Matrícula   | Nome do Acadêmico          |\n",
    "| ----------- | -------------------------- |\n",
    "| **1975660** | Felipe Paes de Lima        |\n",
    "| **3972217** | Marlon Luciano da Silva    |\n",
    "| **4469827** | Nazaré Aline Sá de Azevedo |\n",
    "| **4518087** | Roger da Rosa Szortyka     |\n",
    "| **4525523** | Sandro Loch                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc8f926-af12-499c-a8bb-323fc17b45f0",
   "metadata": {},
   "source": [
    "<center><h1> Previsão de Epidemias de Dengue Utilizando Modelos de Aprendizado de Máquina: Um Estudo com Dados do Sistema Infodengue</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ab239-3f29-44ac-a594-aa377df69465",
   "metadata": {},
   "source": [
    "\n",
    "  A **dengue** é uma doença viral transmitida pelo mosquito Aedes aegypti, que se espalhou rapidamente por todas as regiões do mundo, principalmente nas regiões tropicais e subtropicais. A doença é considerada um grave problema de saúde pública, com impacto significativo na qualidade de vida das pessoas e na economia dos países afetados. Segundo a Organização Mundial da Saúde (OMS), a dengue é a arbovirose urbana mais prevalente nas Américas, com um aumento significativo no número de casos nas últimas décadas. A dengue é uma doença complexa, com múltiplos fatores que influenciam sua transmissão e disseminação. A falta de tratamentos específicos e vacinas eficazes torna a prevenção e o controle da doença ainda mais desafiadores. Nesse contexto, a aplicação de técnicas de Machine Learning pode ser uma ferramenta valiosa para a previsão e prevenção de surtos de dengue. Este trabalho tem como objetivo apresentar um estudo sobre a dengue e a aplicação de técnicas de Machine Learning para previsão e prevenção de surtos da doença. Serão apresentados estudos científicos que discutem a aplicação de técnicas de Machine Learning para previsão e prevenção de surtos de dengue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d74e1-cda1-4b1a-a5c1-8bc33e52c86e",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "O objetivo principal deste projeto é desenvolver modelos de aprendizado de máquina capazes de prever incidências de dengue com base em dados históricos do Sistema Infodengue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b394a3-4bc4-4ae3-9e81-20ebfbfc4e6c",
   "metadata": {},
   "source": [
    "## Especificação Técnica\n",
    "\n",
    "**Métodos de Pré-processamento:** Um dos principais destaques nas tarefas de pré-processamento deste projeto foi a extração e transformação necessárias para obtenção deste conjunto de dados (detalhes na seção *Metodologia para Extração de Dados*). Em posse dos dados, outras operações de pré-processamento foram necessárias, destacando-se:\n",
    "  - [Metodologia para Extração de Dados]()\n",
    "  - [Agrupamento e/ou categorização dos dados]()\n",
    "  - [Tarefas de Aprendizado de Máquina]()\n",
    "  - [Métricas de Avaliação dos metodos de Aprendizado de Máquina]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9fb1d8-19f6-412f-bc76-8f41549a1e0f",
   "metadata": {},
   "source": [
    "## Metodologia para Extração de Dados \n",
    "### 1. Extração, Transformação e Inserção de Dados de Notificações de Casos no Banco de Dados do Infodengue\n",
    "#### Sistema Infodengue usando a API do PySUS por meio do script AlertaDengue\n",
    "\n",
    "Nesta seção, descreveremos detalhadamente o processo de pré-processamento de dados realizado pelo script [AlertaDengue](https://github.com/AlertaDengue/AlertaDengue/blob/main/AlertaDengue/dbf/pysus.py), Os dados são coletados do [DataSUS](https://datasus.saude.gov.br/) por meio da  biblioteca [PySUS](https://github.com/AlertaDengue/pysus), abordando a coleta, tratamento e inserção dos dados, passando por várias transformações que são, por fim, inseridos no banco de dados da dengue no sistema [Infodengue](https://info.dengue.mat.br/informacoes/), utilizando o PostgreSQL como mecanismo de gerenciamento de banco de dados.\n",
    "\n",
    "- **Coleta de Dados** : O script inicia o processo de pré-processamento coletando dados do DataSUS. Isso envolve a aquisição de informações sobre casos de doenças específicas, como dengue, chikungunya e zika, para um determinado ano.\n",
    "- **Cálculo de Campos Relevantes** : Os dados coletados não estão prontos para serem inseridos no banco de dados do sistema Infodengue. Portanto, o script executa uma série de cálculos para criar campos adicionais e corrigir dados inconsistentes ou mal formatados. Isso inclui o cálculo da data de nascimento com base na idade do paciente, a adição de dígitos verificadores aos geocódigos municipais e a correção de códigos CID10 de doenças.\n",
    "- **Transformação de Dados** : O script realiza transformações nos dados para garantir que eles atendam aos requisitos do sistema Infodengue. Isso inclui a padronização de campos, como a representação da semana epidemiológica brasileira.\n",
    "- **Inserção no Banco de Dados** : Após a coleta e transformação dos dados, o script estabelece uma conexão com o banco de dados PostgreSQL do sistema Infodengue. Ele insere os dados pré-processados no banco de dados, seguindo uma estratégia de inserção que evita a duplicação de registros. Isso garante que os dados estejam prontos para análises futuras e disponíveis para consulta no sistema Infodengue.\n",
    "- **Registro de Erros**: Durante o processo de pré-processamento e inserção, o script monitora possíveis erros ou exceções. Em caso de erro, ele registra informações detalhadas em um arquivo de log para fins de depuração e auditoria.\n",
    "\n",
    "### Bibliotecas Usadas no AlertaDengue (Notificações de Casos):\n",
    "#### **Para realizar essas operações, o [script](https://github.com/AlertaDengue/AlertaDengue/blob/main/AlertaDengue/dbf/pysus.py) faz uso das seguintes bibliotecas**:\n",
    "\n",
    "- **numpy (np)** : Esta biblioteca é amplamente usada para cálculos matemáticos e operações em arrays multidimensionais. No contexto deste script, o numpy é utilizado para efetuar cálculos em campos como idade e geocódigos municipais.\n",
    "\n",
    "- **pandas (pd)** : O pandas é uma biblioteca poderosa para manipulação e análise de dados. Aqui, o pandas é empregado para estruturar e limpar os dados, incluindo a seleção de colunas relevantes, ajuste de tipos de dados e tratamento de valores ausentes.\n",
    "\n",
    "- **psycopg2** : Essa biblioteca possibilita a conexão com um banco de dados PostgreSQL. O script a utiliza para se conectar ao banco de dados do sistema Infodengue e inserir os dados processados.\n",
    "\n",
    "- **pathlib** : A biblioteca pathlib é usada para lidar com caminhos de arquivo e diretório de forma eficiente. Ela auxilia na organização e manipulação de arquivos, incluindo a leitura de arquivos Parquet e a criação de diretórios para armazenamento temporário.\n",
    "\n",
    "- **datetime e timedelta** : Essas bibliotecas nativas do Python são usadas para manipulação de datas e horários. São fundamentais para calcular datas de nascimento a partir da idade dos pacientes e para calcular datas epidemiológicas.\n",
    "\n",
    "- **glob** : A biblioteca glob é útil para pesquisa de arquivos em um diretório com base em padrões de nome de arquivo. Aqui, ela é usada para encontrar e processar múltiplos arquivos Parquet com dados do DataSUS.\n",
    "\n",
    "- **logging** : O módulo de logging é usado para registrar informações relevantes durante a execução do script, auxiliando na depuração e no monitoramento.\n",
    "\n",
    "- **settings (AlertaDengue.ad_main)** : Essa importação específica refere-se a configurações personalizadas definidas nas conficurações principais do projeto AlertaDengue. Essas configurações incluem detalhes de conexão com o banco de dados PostgreSQL.\n",
    "\n",
    "- **episem (AlertaDengue.dados.episem)** : A biblioteca episem é utilizada para cálculos relacionados a semanas epidemiológicas, que são cruciais para a análise de dados relacionados à dengue.\n",
    "\n",
    "- **SINAN (pysus.online_data)** : SINAN é uma ferramenta que permite o acesso a dados online, ncluindo a obtenção de dados do DataSUS. Neste contexto, ele é usado para baixar dados relacionados à dengue.\n",
    "\n",
    "### 2. Extração, Transformação e Inserção de Dados Climáticos no Banco de Dados do Infodengue\n",
    "#### Sistema Infodengue usando a API do Copernicus por meio do script Satellite-Weather-Downloader\n",
    "\n",
    "O [Satellite-Weather-Downloader](https://github.com/osl-incubator/satellite-weather-downloader) captura os dados meteorológicos da API [Copernicus](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels). Esta biblioteca oferece funcionalidades para capturar, converter e processar os dados para uso em análises meteorológicas no contexto brasileiro.\n",
    "\n",
    "Os principais componentes e funcionalidades do [script](https://github.com/osl-incubator/satellite-weather-downloader/blob/main/satellite/weather/copebr.py#L230\n",
    ") Satellite-Weather-Downloader incluem:\n",
    "\n",
    "- **CopeBRDatasetExtension** : Esta classe é uma extensão para objetos xr.Dataset que permite adicionar funcionalidades específicas do Brasil para dados meteorológicos.\n",
    "\n",
    "- **Métodos como to_dataframe e to_sql** : Permitem converter os dados do conjunto de dados xarray em estruturas de dados como DataFrames do Pandas e inseri-los em um banco de dados SQL, respectivamente.\n",
    "\n",
    "- **Métodos como _geocode_ds e _geocode_to_dataframe** : São usados para processar e extrair dados meteorológicos específicos para uma localização geográfica (identificada pelo IBGE geocode).\n",
    "\n",
    "- **_convert_to_br_units** : É usado para converter unidades de medidas para padrões brasileiros, como a conversão de Kelvin para Celsius, metros para milímetros e Pascal para ATM.\n",
    "\n",
    "- **_get_latlons** : Extrai as coordenadas de latitude e longitude para um determinado geocode IBGE de uma cidade brasileira.\n",
    "\n",
    "*Destacamos a **função _convert_to_br_units** que é responsável por converter unidades de medidas em um conjunto de dados xarray para padrões brasileiros. Isso é importante porque as unidades de medidas usadas em dados meteorológicos podem variar dependendo da origem dos dados, e é útil padronizá-las para uma análise mais consistente no contexto brasileiro.*\n",
    "\n",
    "#### Explicação passo a passo do que esta função faz:\n",
    "\n",
    "  1. Recebe um conjunto de dados xr.Dataset como entrada.\n",
    "  2. Verifica quais variáveis de dados estão presentes no conjunto de dados (por meio da lista de nomes das variáveis vars).\n",
    "  3. Para cada variável presente no conjunto de dados, verifica se ela corresponde a alguma variável específica de acordo com seu nome (por exemplo, \"t2m\" para temperatura em Kelvin, \"tp\" para precipitação em metros, \"msl\" para pressão em Pascal).\n",
    "  4. Se uma variável corresponder a alguma dessas variáveis específicas, a função realiza as seguintes conversões de unidades:\n",
    "  5. Para \"t2m\" (temperatura em Kelvin), ela converte para Celsius subtraindo 273.15 e define as unidades e o nome longo apropriados.\n",
    "  6. Para \"d2m\" (temperatura do ponto de orvalho em Kelvin), ela realiza o mesmo cálculo de conversão para Celsius e também calcula a umidade relativa do ar em porcentagem usando a fórmula de Buck.\n",
    "  7. Para \"tp\" (precipitação em metros), ela converte para milímetros multiplicando por 1000 e arredonda para 5 casas decimais. Também define as unidades e o nome longo apropriados.\n",
    "  8. Para \"msl\" (pressão ao nível do mar em Pascal), ela converte para ATM multiplicando por um fator específico e define as unidades e o nome longo apropriados.\n",
    "\n",
    "*A função retorna o conjunto de dados resultante com as unidades convertidas e os nomes convencionados.*\n",
    "\n",
    "### Bibliotecas Usadas no Satellite-Weather-Downloader (Captura de dados Climáticos):\n",
    "#### Para realizar essas operações, o script faz uso das seguintes bibliotecas:\n",
    "\n",
    "\n",
    "- **dask** : Utilizado para computação paralela e assíncrona, útil para processamento eficiente de grandes volumes de dados.\n",
    "\n",
    "- **dask.array** : Oferece suporte para arrays Dask, que são úteis para computação paralela em dados multidimensionais, como dados climáticos.\n",
    "\n",
    "- **dask.dataframe** : Usado para trabalhar com estruturas de dados semelhantes a DataFrames em um ambiente Dask.\n",
    "\n",
    "- **numpy** : Amplamente utilizado para cálculos matemáticos e operações em arrays multidimensionais.\n",
    "\n",
    "- **xarray** : Essencial para trabalhar com dados multidimensionais, como dados climáticos, de forma eficiente.\n",
    "\n",
    "- **loguru** : Biblioteca de registro de eventos usada para registrar informações durante a execução do script, auxiliando na depuração e no monitoramento.\n",
    "\n",
    "- **sqlalchemy.engine.Connectable** : Usado para estabelecer conexões com bancos de dados SQL, como o PostgreSQL, para inserir dados processados.\n",
    "\n",
    "**Essas bibliotecas desempenham papéis essenciais no processamento e preparação dos dados antes de serem inseridos no sistema Infodengue, garantindo que estejam prontos para análise e consulta.**\n",
    "\n",
    "Em resumo, o pré-processamento de dados realizado pelos scripts é uma etapa crítica que visa garantir a qualidade, consistência e integridade dos dados coletados antes de serem incorporados ao banco de dados do sistema Infodengue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452b6a3-bb3b-4a70-86a8-0517f928b1b8",
   "metadata": {},
   "source": [
    "## Agrupamento e/ou categorização dos dados\n",
    "### Consulta no banco de dados Infodengue e exportação do conjunto de dados em formato CSV\n",
    "Para a obtenção dos dados relevantes necessários para o treinamento dos modelos de machine learning, foi criado uma função **weather_notific** especifica no script do repositório [ml-dengue-predict](https://github.com/esloch/ml-dengue-predict) para selecionar e filtrar os campos e dados pertinentes em uma série temporal. Essa série temporal abrange um período significativo, de 2010 a 2023, e envolve quatro estados e, os campos selecionados incluem informações de Notificações e Varáveis Climáticas.\n",
    "\n",
    "Após a recuperação desses dados, eles são exportados para um arquivo CSV. Esse arquivo CSV contém os dados que serão usados no treinamento dos modelos de machine learning, permitindo análises avançadas e a criação de modelos preditivos relacionados à dengue e outras doenças transmitidas por vetores. \n",
    "\n",
    "\n",
    "Para isso e script [fetchinfodata.py](https://github.com/esloch/ml-dengue-predict/blob/main/fetchinfodata/fetchinfodata.py) é responsável por recuperar dados de clima e notificação para um estado específico e um intervalo de datas fornecido. Ele realiza uma consulta que envolve várias junções de tabelas para combinar dados meteorológicos e de notificação relevantes para análises posteriores.\n",
    "\n",
    "### Detalhes do conjunto de dados (Dataset)\n",
    "\n",
    "- Import pandas as *pd* and use the **read_csv** function to open the dataset\n",
    "\n",
    "    ![](https://hackmd.io/_uploads/ry71hMfR2.png)</br>\n",
    "        <small>fonte: *pandas.read_csv /* [pandas.pydata.org](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas-read-csv) </small>\n",
    "    \n",
    "- Prints information about a DataFrame including the index dtype and columns, non-null values and memory usage \n",
    "\n",
    "\n",
    "    ![](https://hackmd.io/_uploads/SJK6NMzR3.png)</br> \n",
    "    <small>fonte: *pandas.DataFrame.info /* [pandas.pydata.org](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html#pandas-dataframe-info) </small>\n",
    "\n",
    " - Returns the first n rows for the object based on position: \n",
    "\n",
    "    ![](https://hackmd.io/_uploads/rJIEDfz0h.png)\n",
    "    <small>fonte: *pandas.DataFrame.head /* [pandas.pydata.org](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html#pandas-dataframe-head) </small>\n",
    "\n",
    "**Descrição das Features**: A tabela abaixo fornece mais detalhes sobre a composição do conjunto de dados que será utilizado no treinamento dos modelos de machine learning. \n",
    "\n",
    "| **Coluna**     | **Tipo**         | **Descrição**                                                           | **Exemplo**  |\n",
    "|----------------|------------------|-------------------------------------------------------------------------|--------------|\n",
    "| uf             | texto (str)      | Nome da unidade federativa do Brasil                                    | Santa Catarina |\n",
    "| geocodigo      | número (int64)   | Código IBGE associado aos município brasileiros composto por 7 digitos  | 4209102      |\n",
    "| nome_municipio | texto (str)      | Nome do município                                                       | Joinville    |\n",
    "| dt_notific     | data (Timestamp) | Data da notificação em format ISO 8601                                  | 2020-07-22   |\n",
    "| se_notif       | número (int64)   | Semana em que ocorreu a notificação                                     | 18           |\n",
    "| ano_notif      | número (int64)   | Ano em que ocorreu a notificação                                        | 2022         |\n",
    "| temp_med       | número (float64) | Temperatura média em graus Celsius                                      | 20.466202    |\n",
    "| precip_med     | número (float64) | Precipitação média                                                      | 0.035414     |\n",
    "| pressao_med    | número (float64) | Pressão atmosférica média                                               | 1.005391     |\n",
    "| umid_med       | número (float64) | Umidade relativa do ar média                                            | 87.35066     |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a1916f-42d2-4313-bbd4-12f056efc6d4",
   "metadata": {},
   "source": [
    "## Avaliação dos Metodos de aprendizado de máquina\n",
    "**Modo de Aprendizado**: Supervisionado\n",
    "\n",
    "**Tarefa de Aprendizado:** Será aplicada a tarefa de Regressão\n",
    "\n",
    "**Algoritmos Avaliados:** Random Forest, Lasso, Linear Regression  \n",
    "\n",
    "**Métricas Utilizadas:** Erro quadrático médio (MSE, do inglês mean squared error), raiz do erro quadrático médio (RMSE, do inglês Root Mean Squared Error) e erro absoluto médio (MAE, do inglês median absolute error). (Nogueira, 2020. p. 132)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4a201-072a-466a-9f8f-647e606c8bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
